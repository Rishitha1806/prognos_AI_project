{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Implementation of GRU on the time-series dataset"
      ],
      "metadata": {
        "id": "y0BfI7o53IDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "_Pc6uLYy3Mqt"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9ht19gluJcwB"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "X = np.load('/content/drive/MyDrive/data/datasave/rolling_window_sequences.npy')\n",
        "metadata = pd.read_csv('/content/drive/MyDrive/data/datasave/sequence_metadata_with_RUL.csv')\n",
        "y = metadata['RUL'].values"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "8tGuA3Sm4K65"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define GRU model\n",
        "def create_gru_model(input_shape, units=64, learning_rate=0.01, dropout_rate=0.2):\n",
        "  model = Sequential()\n",
        "  model.add(GRU(units, input_shape=input_shape, return_sequences=True))\n",
        "  model.add(Dropout(dropout_rate))\n",
        "  model.add(Dense(1))\n",
        "  optimizer = Adam(learning_rate=learning_rate)\n",
        "  model.compile(loss='mse', optimizer=optimizer, metrics=['mae'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "ce3PryU44Pre"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "model = create_gru_model(input_shape=(X_train.shape[1], X_train.shape[2]), units=64, learning_rate=0.001, dropout_rate=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8p4UPKzo4Vgo",
        "outputId": "9bbbad02-bc24-4922-91d3-32e60e31ce35"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Callbacks\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "callbacks= [\n",
        "    EarlyStopping(monitor='val_loss', patience=10, verbose=1),\n",
        "    ModelCheckpoint('best_gru_model.keras', save_best_only=True, monitor=\"val_loss\", verbose=1)\n",
        "]"
      ],
      "metadata": {
        "id": "fuYD3OA44dVz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data = (X_test, y_test),\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    verbose=1,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLJq23Rc4md3",
        "outputId": "65a01546-2bae-41f7-9bfc-a723f00423d9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m385/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 11420.7871 - mae: 87.6842\n",
            "Epoch 1: val_loss improved from inf to 8223.44043, saving model to best_gru_model.keras\n",
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 33ms/step - loss: 11414.0840 - mae: 87.6475 - val_loss: 8223.4404 - val_mae: 70.9468\n",
            "Epoch 2/50\n",
            "\u001b[1m385/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 7833.1294 - mae: 68.4071\n",
            "Epoch 2: val_loss improved from 8223.44043 to 6231.09424, saving model to best_gru_model.keras\n",
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 34ms/step - loss: 7830.4922 - mae: 68.3956 - val_loss: 6231.0942 - val_mae: 60.6559\n",
            "Epoch 3/50\n",
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 6065.3159 - mae: 59.7456\n",
            "Epoch 3: val_loss improved from 6231.09424 to 5016.25830, saving model to best_gru_model.keras\n",
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - loss: 6064.4492 - mae: 59.7417 - val_loss: 5016.2583 - val_mae: 54.7416\n",
            "Epoch 4/50\n",
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 4816.1313 - mae: 53.7977\n",
            "Epoch 4: val_loss improved from 5016.25830 to 4323.97266, saving model to best_gru_model.keras\n",
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 32ms/step - loss: 4816.0396 - mae: 53.7976 - val_loss: 4323.9727 - val_mae: 51.5742\n",
            "Epoch 5/50\n",
            "\u001b[1m385/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4428.6260 - mae: 52.3437\n",
            "Epoch 5: val_loss improved from 4323.97266 to 3958.70142, saving model to best_gru_model.keras\n",
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 29ms/step - loss: 4427.7471 - mae: 52.3394 - val_loss: 3958.7014 - val_mae: 50.1713\n",
            "Epoch 6/50\n",
            "\u001b[1m384/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 4063.2925 - mae: 50.7535\n",
            "Epoch 6: val_loss improved from 3958.70142 to 3809.87402, saving model to best_gru_model.keras\n",
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 36ms/step - loss: 4062.8430 - mae: 50.7526 - val_loss: 3809.8740 - val_mae: 49.8014\n",
            "Epoch 7/50\n",
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3964.1711 - mae: 50.7269\n",
            "Epoch 7: val_loss improved from 3809.87402 to 3759.64111, saving model to best_gru_model.keras\n",
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 31ms/step - loss: 3964.0332 - mae: 50.7262 - val_loss: 3759.6411 - val_mae: 49.7959\n",
            "Epoch 8/50\n",
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3828.4395 - mae: 50.1658\n",
            "Epoch 8: val_loss improved from 3759.64111 to 3746.99512, saving model to best_gru_model.keras\n",
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 31ms/step - loss: 3828.5757 - mae: 50.1667 - val_loss: 3746.9951 - val_mae: 49.8671\n",
            "Epoch 9/50\n",
            "\u001b[1m384/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3894.7722 - mae: 50.6393\n",
            "Epoch 9: val_loss improved from 3746.99512 to 3744.78491, saving model to best_gru_model.keras\n",
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 31ms/step - loss: 3894.6165 - mae: 50.6391 - val_loss: 3744.7849 - val_mae: 49.9169\n",
            "Epoch 10/50\n",
            "\u001b[1m384/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3865.6777 - mae: 50.5156\n",
            "Epoch 10: val_loss improved from 3744.78491 to 3744.54053, saving model to best_gru_model.keras\n",
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 33ms/step - loss: 3865.7344 - mae: 50.5166 - val_loss: 3744.5405 - val_mae: 49.9379\n",
            "Epoch 11/50\n",
            "\u001b[1m385/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3786.2878 - mae: 50.1394\n",
            "Epoch 11: val_loss did not improve from 3744.54053\n",
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 31ms/step - loss: 3786.7349 - mae: 50.1421 - val_loss: 3744.5598 - val_mae: 49.9565\n",
            "Epoch 12/50\n",
            "\u001b[1m385/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3881.3533 - mae: 50.6549\n",
            "Epoch 12: val_loss did not improve from 3744.54053\n",
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - loss: 3881.3071 - mae: 50.6550 - val_loss: 3744.5430 - val_mae: 49.9530\n",
            "Epoch 13/50\n",
            "\u001b[1m384/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3813.0220 - mae: 50.4189\n",
            "Epoch 13: val_loss did not improve from 3744.54053\n",
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 34ms/step - loss: 3813.4797 - mae: 50.4208 - val_loss: 3744.6250 - val_mae: 49.9649\n",
            "Epoch 14/50\n",
            "\u001b[1m385/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3909.8647 - mae: 51.1482\n",
            "Epoch 14: val_loss did not improve from 3744.54053\n",
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 32ms/step - loss: 3909.6733 - mae: 51.1458 - val_loss: 3744.5439 - val_mae: 49.9538\n",
            "Epoch 15/50\n",
            "\u001b[1m385/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3913.6973 - mae: 50.7836\n",
            "Epoch 15: val_loss did not improve from 3744.54053\n",
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 30ms/step - loss: 3913.4834 - mae: 50.7830 - val_loss: 3744.7007 - val_mae: 49.9714\n",
            "Epoch 16/50\n",
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3916.9224 - mae: 51.0707\n",
            "Epoch 16: val_loss improved from 3744.54053 to 3744.52466, saving model to best_gru_model.keras\n",
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 32ms/step - loss: 3916.8069 - mae: 51.0697 - val_loss: 3744.5247 - val_mae: 49.9413\n",
            "Epoch 17/50\n",
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3827.2571 - mae: 50.5059\n",
            "Epoch 17: val_loss improved from 3744.52466 to 3744.22388, saving model to best_gru_model.keras\n",
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 30ms/step - loss: 3827.3760 - mae: 50.5064 - val_loss: 3744.2239 - val_mae: 49.9530\n",
            "Epoch 18/50\n",
            "\u001b[1m385/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3968.6299 - mae: 51.1779\n",
            "Epoch 18: val_loss improved from 3744.22388 to 3743.26050, saving model to best_gru_model.keras\n",
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 31ms/step - loss: 3968.1304 - mae: 51.1753 - val_loss: 3743.2605 - val_mae: 49.9007\n",
            "Epoch 19/50\n",
            "\u001b[1m385/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3845.7585 - mae: 50.3561\n",
            "Epoch 19: val_loss did not improve from 3743.26050\n",
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 30ms/step - loss: 3845.8938 - mae: 50.3576 - val_loss: 3743.7600 - val_mae: 49.9702\n",
            "Epoch 20/50\n",
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3992.3149 - mae: 51.4564\n",
            "Epoch 20: val_loss did not improve from 3743.26050\n",
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 32ms/step - loss: 3992.0020 - mae: 51.4544 - val_loss: 3743.7048 - val_mae: 49.8705\n",
            "Epoch 21/50\n",
            "\u001b[1m385/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3756.9619 - mae: 50.0419\n",
            "Epoch 21: val_loss did not improve from 3743.26050\n",
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 32ms/step - loss: 3757.5576 - mae: 50.0450 - val_loss: 3743.5354 - val_mae: 49.9610\n",
            "Epoch 22/50\n",
            "\u001b[1m385/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3830.2903 - mae: 50.0511\n",
            "Epoch 22: val_loss improved from 3743.26050 to 3742.78076, saving model to best_gru_model.keras\n",
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 33ms/step - loss: 3830.5051 - mae: 50.0543 - val_loss: 3742.7808 - val_mae: 49.9178\n",
            "Epoch 23/50\n",
            "\u001b[1m384/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3872.8450 - mae: 50.5423\n",
            "Epoch 23: val_loss improved from 3742.78076 to 3742.65479, saving model to best_gru_model.keras\n",
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 27ms/step - loss: 3872.8276 - mae: 50.5431 - val_loss: 3742.6548 - val_mae: 49.9126\n",
            "Epoch 24/50\n",
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3852.9509 - mae: 50.4100\n",
            "Epoch 24: val_loss did not improve from 3742.65479\n",
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 29ms/step - loss: 3852.9998 - mae: 50.4106 - val_loss: 3743.4912 - val_mae: 49.9776\n",
            "Epoch 25/50\n",
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3971.1248 - mae: 51.6247\n",
            "Epoch 25: val_loss did not improve from 3742.65479\n",
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 31ms/step - loss: 3970.8684 - mae: 51.6223 - val_loss: 3742.8079 - val_mae: 49.9367\n",
            "Epoch 26/50\n",
            "\u001b[1m384/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3861.7107 - mae: 50.4550\n",
            "Epoch 26: val_loss did not improve from 3742.65479\n",
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 31ms/step - loss: 3861.7932 - mae: 50.4566 - val_loss: 3743.2048 - val_mae: 49.9653\n",
            "Epoch 27/50\n",
            "\u001b[1m384/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3780.9878 - mae: 50.2918\n",
            "Epoch 27: val_loss did not improve from 3742.65479\n",
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 31ms/step - loss: 3781.6919 - mae: 50.2948 - val_loss: 3743.0815 - val_mae: 49.9596\n",
            "Epoch 28/50\n",
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3928.7212 - mae: 51.0499\n",
            "Epoch 28: val_loss improved from 3742.65479 to 3742.58032, saving model to best_gru_model.keras\n",
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 30ms/step - loss: 3928.5710 - mae: 51.0489 - val_loss: 3742.5803 - val_mae: 49.9218\n",
            "Epoch 29/50\n",
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 3789.0339 - mae: 50.4065\n",
            "Epoch 29: val_loss did not improve from 3742.58032\n",
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 35ms/step - loss: 3789.2456 - mae: 50.4070 - val_loss: 3743.3494 - val_mae: 49.9777\n",
            "Epoch 30/50\n",
            "\u001b[1m385/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3932.8838 - mae: 51.1746\n",
            "Epoch 30: val_loss did not improve from 3742.58032\n",
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 34ms/step - loss: 3932.5693 - mae: 51.1721 - val_loss: 3742.6436 - val_mae: 49.9339\n",
            "Epoch 31/50\n",
            "\u001b[1m385/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3827.6787 - mae: 50.4881\n",
            "Epoch 31: val_loss did not improve from 3742.58032\n",
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 34ms/step - loss: 3827.9084 - mae: 50.4891 - val_loss: 3742.7615 - val_mae: 49.9395\n",
            "Epoch 32/50\n",
            "\u001b[1m384/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3924.3777 - mae: 51.0468\n",
            "Epoch 32: val_loss did not improve from 3742.58032\n",
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 32ms/step - loss: 3923.9702 - mae: 51.0439 - val_loss: 3743.1074 - val_mae: 49.9465\n",
            "Epoch 33/50\n",
            "\u001b[1m384/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3891.3955 - mae: 50.6530\n",
            "Epoch 33: val_loss did not improve from 3742.58032\n",
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 33ms/step - loss: 3891.2478 - mae: 50.6533 - val_loss: 3743.0835 - val_mae: 49.9515\n",
            "Epoch 34/50\n",
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3965.5713 - mae: 51.2373\n",
            "Epoch 34: val_loss did not improve from 3742.58032\n",
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 32ms/step - loss: 3965.3284 - mae: 51.2358 - val_loss: 3743.2224 - val_mae: 49.9581\n",
            "Epoch 35/50\n",
            "\u001b[1m385/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3905.2930 - mae: 50.8365\n",
            "Epoch 35: val_loss did not improve from 3742.58032\n",
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 31ms/step - loss: 3905.1174 - mae: 50.8356 - val_loss: 3743.1101 - val_mae: 49.9544\n",
            "Epoch 36/50\n",
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3896.6321 - mae: 51.0848\n",
            "Epoch 36: val_loss did not improve from 3742.58032\n",
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 28ms/step - loss: 3896.5659 - mae: 51.0837 - val_loss: 3742.9490 - val_mae: 49.9192\n",
            "Epoch 37/50\n",
            "\u001b[1m384/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3989.9363 - mae: 51.2605\n",
            "Epoch 37: val_loss did not improve from 3742.58032\n",
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 32ms/step - loss: 3989.0151 - mae: 51.2559 - val_loss: 3743.2495 - val_mae: 49.9591\n",
            "Epoch 38/50\n",
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3827.7295 - mae: 50.2407\n",
            "Epoch 38: val_loss did not improve from 3742.58032\n",
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 29ms/step - loss: 3827.8413 - mae: 50.2418 - val_loss: 3743.3398 - val_mae: 49.9712\n",
            "Epoch 38: early stopping\n"
          ]
        }
      ]
    }
  ]
}